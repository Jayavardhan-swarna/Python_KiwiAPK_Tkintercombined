{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963c9e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"Mission Credit Card Fraud Detection\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57b5d960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1)preprocessing\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c213fbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge scikit-fuzzy\n",
    "!conda install -c \"conda-forge/label/gcc7\" scikit-fuzzy\n",
    "!conda install -c \"conda-forge/label/cf201901\" scikit-fuzzy\n",
    "!conda install -c \"conda-forge/label/cf202003\" scikit-fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dff096",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2)importing dataset\n",
    "data = pd.read_csv(r\"D:\\\\Data-Engineering\\\\Machine_Learning\\\\project\\\\creditcard_csv.csv\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c66b459",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['Class'].value_counts()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545880f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3)checking if any error present in the data \n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2459b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4)features vs target (or) Dependent vs independent variable \n",
    "X = data.iloc[:, 1:30].columns                               #[column(top:bottom), row(left:right)]\n",
    "X = data[X] \n",
    "y = data['Class']\n",
    "\n",
    "print(X)\n",
    "print(\"---------------------------------------------------------------------------------------------\")\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c985ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e7c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5)spliting data into training & testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07c8374",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6)feature scaling\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(X_train)\n",
    "x_test = sc.transform(X_test)\n",
    "\n",
    "print(X_train)\n",
    "print(\"---------------------------------------------------------------------------------------------\")\n",
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa3683a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7)using particular algorithm(Logistic Regression)\n",
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5d24be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#8)Training the model\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2864d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#9)predicting the model through testing\n",
    "y_pred = clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8e0588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10)comparing the predicted o/p & actual excel o/p   (9th point vs 10th point)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d7f2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10)comparing the predicted o/p & actual excel o/p   (9th point vs 10th point)\n",
    "a = clf.predict([[-1.359807134, -0.072781173, 2.536346738, 1.378155224, -0.33832077, 0.462387778, 0.239598554, 0.098697901\n",
    ",0.36378697, 0.090794172, -0.551599533, -0.617800856, -0.991389847, -0.311169354, 1.468176972, -0.470400525, 0.207971242,\n",
    "0.02579058, 0.40399296, 0.251412098,-0.018306778, 0.277837576, -0.11047391, 0.066928075, 0.128539358, -0.189114844, 0.133558377,\n",
    "-0.021053053, 149.62]])\n",
    "if a == ([\"'0'\"]):\n",
    "    print(a, \"==\" ,\" You are not a fraud, Don't worry, Go to the airport!!!!!!ðŸ˜Š ðŸ˜Š ðŸ˜Š ðŸ˜Š ðŸ˜Š\")\n",
    "else:\n",
    "    print(a, \"==\" , \"You are a fraud, Do worry, police take him to custody!!!!!!ðŸ˜  ðŸ˜  ðŸ˜  ðŸ˜  ðŸ˜  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f820b4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10)comparing the predicted o/p & actual excel o/p   (9th point vs 10th point)\n",
    "b = clf.predict([[-10.359807134, -01.072781173, 12.536346738, 11.378155224, -0.33832077, 0.462387778, 0.239598554, 0.098697901\n",
    ",10.36378697, 10.090794172, -0.551599533, -10.617800856, -0.991389847, -10.311169354, 1.468176972, -0.470400525, 0.207971242,\n",
    "10.02579058, 0.40399296, 10.951412098,-10.918306778, 0.277837576, -0.11047391, 10.066928075, 10.128539358, -0.189114844, 0.133558377,\n",
    "-0.021053053, 149.62]])\n",
    "if b == ([\"'0'\"]):\n",
    "    print(b, \"==\",\" You are not a fraud, Don't worry, Go to the airport!!!!!!ðŸ˜Š ðŸ˜Š ðŸ˜Š ðŸ˜Š ðŸ˜Š\")\n",
    "else:\n",
    "    print(b, \"==\", \"You are a fraud, Do worry, police take him to custody!!!!!! ðŸ˜  ðŸ˜  ðŸ˜  ðŸ˜  ðŸ˜  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2563ac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11)confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "accuracy_score(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349266cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11)confusion matrix\n",
    "cm = (metrics.confusion_matrix(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\\n\",cm,\"\\n\")\n",
    "\n",
    "accuracy=(cm[0][0]+cm[1][1])/(cm[0][0]+cm[1][1]+cm[0][1]+cm[1] [0])\n",
    "print(\"Accuracy:\",accuracy)\n",
    "\n",
    "precision=(cm[0][0])/(cm[0][0]+cm[0][1])\n",
    "print(\"Precision:\",precision)\n",
    "\n",
    "Recall=(cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "print(\"Recall:\",Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4db532",
   "metadata": {},
   "outputs": [],
   "source": [
    "#12)classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3839a042",
   "metadata": {},
   "outputs": [],
   "source": [
    "#13)heat map for confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.show()#print the actual and predicted labels\n",
    "df1 = pd.DataFrame({'Actual':y_test, 'Predicted': y_pred})\n",
    "print(df1.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ad0a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the model 2 (Random Forest)\n",
    "random_forest = RandomForestClassifier(n_estimators = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863c247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier\n",
    "random_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5746be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the model\n",
    "y_pred = random_forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be1e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "cm = (metrics.confusion_matrix(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\\n\",cm,\"\\n\")\n",
    "print(cm)\n",
    "accuracy=(cm[0][0]+cm[1][1])/(cm[0][0]+cm[1][1]+cm[0][1]+cm[1] [0])\n",
    "print(\"Accuracy:\",accuracy)\n",
    "precision=(cm[0][0])/(cm[0][0]+cm[0][1])\n",
    "print(\"Precision:\",precision)\n",
    "Recall=(cm[0][0])/(cm[0][0]+cm[1][0])\n",
    "print(\"Recall:\",Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204bdd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c3db05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy score \n",
    "a= (metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Accuracy score:\",round(a,1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e20b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#heat map for confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(7,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d71614d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the actual and predicted labels\n",
    "df1 = pd.DataFrame({'Actual':y_test, 'Predicted': y_pred}) \n",
    "print(df1.head(5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
